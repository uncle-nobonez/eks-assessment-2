name: Terraform Infrastructure

on:
  push:
    branches: [ main ]
    paths: [ 'terraform/**' ]
  pull_request:
    branches: [ main ]
    paths: [ 'terraform/**' ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  TF_VERSION: 1.5.0

jobs:
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: terraform/eks/minimal
      run: |
        terraform init

    - name: Terraform Plan
      working-directory: terraform/eks/minimal
      run: |
        terraform plan -out=tfplan -no-color
        terraform show -no-color tfplan
      continue-on-error: true

  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: terraform/eks/minimal
      run: |
        terraform init

    - name: Clean Existing EKS Resources
      run: |
        echo "Deleting existing EKS cluster and related resources"
        # Delete all node groups first
        for nodegroup in $(aws eks list-nodegroups --cluster-name retail-store --query 'nodegroups[]' --output text 2>/dev/null || true); do
          echo "Deleting nodegroup: $nodegroup"
          aws eks delete-nodegroup --cluster-name retail-store --nodegroup-name $nodegroup || true
        done
        
        # Wait for node groups to be deleted
        echo "Waiting for node groups to be deleted..."
        sleep 60
        
        # Delete the EKS cluster
        aws eks delete-cluster --name retail-store || true
        
        # Wait for cluster deletion to complete
        echo "Waiting for EKS cluster to be deleted..."
        for i in {1..15}; do
          if ! aws eks describe-cluster --name retail-store >/dev/null 2>&1; then
            echo "EKS cluster deleted successfully"
            break
          fi
          echo "Cluster still exists, waiting... (attempt $i/15)"
          sleep 30
        done
        
        # Delete KMS alias
        aws kms delete-alias --alias-name alias/eks/retail-store || true
        
        # Delete ADOT IAM roles
        echo "Deleting ADOT IAM roles..."
        # Detach policies first
        aws iam list-attached-role-policies --role-name retail-store-adot-col-xray --query 'AttachedPolicies[].PolicyArn' --output text 2>/dev/null | xargs -r -n1 aws iam detach-role-policy --role-name retail-store-adot-col-xray --policy-arn || true
        aws iam list-attached-role-policies --role-name retail-store-adot-col-logs --query 'AttachedPolicies[].PolicyArn' --output text 2>/dev/null | xargs -r -n1 aws iam detach-role-policy --role-name retail-store-adot-col-logs --policy-arn || true
        # Delete roles
        aws iam delete-role --role-name retail-store-adot-col-xray || true
        aws iam delete-role --role-name retail-store-adot-col-logs || true
        
        echo "Cleanup completed"

    - name: Terraform Apply
      working-directory: terraform/eks/minimal
      run: |
        # Force unlock any existing state locks
        terraform force-unlock -force 453ffb36-4889-20eb-56e9-66b0915f73a4 || true
        
        if [ -f tfplan ]; then
          echo "Applying from saved plan tfplan"
          terraform apply -auto-approve tfplan
        else
          echo "No saved plan found; running terraform apply -auto-approve"
          terraform apply -auto-approve
        fi

    - name: Output cluster info
      working-directory: terraform/eks/minimal
      run: |
        echo "EKS Cluster deployed successfully!"
        terraform output configure_kubectl